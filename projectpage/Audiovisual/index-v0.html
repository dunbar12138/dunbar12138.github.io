<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 800px;
	}
	
	h1 {
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		        15px 15px 0 0px #fff, /* The fourth layer */
		        15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		        20px 20px 0 0px #fff, /* The fifth layer */
		        20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		        25px 25px 0 0px #fff, /* The fifth layer */
		        25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
	    top: 50%;
	    transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
  <head>
		<title>Audiovisual Synthesis</title>
		<meta property="og:title" content="Audiovisual Synthesis " />
  </head>

  <body>
    <br>
          <center>
          	<span style="font-size:42px">Unsupervised Audiovisual Synthesis via Exemplar Autoencoders</span>
	  		  <table align=center width=600px>
	  			  <tr>
	  	              <td align=center width=100px>
	  					<center>
							<span style="font-size:20px"><a href="https://dunbar12138.github.io/">Kangle Deng</a></span>
		  		  		</center>
						  </td>
	  	              <td align=center width=100px>
	  					<center>
							<span style="font-size:20px"><a href="http://www.cs.cmu.edu/~aayushb/">Aayush Bansal</a></span>
		  		  		</center>
						  </td>
						<td align=center width=100px>
							<center>
								<span style="font-size:20px"><a href="http://www.cs.cmu.edu/~deva/">Deva Ramanan</a></span>
								</center>
						</td>
			  </table>

	  		  <table align=center width=400px>
	  			  <tr>
	  	              <td align=center width=150px>
	  					<center>
	  						<span style="font-size:24px"><a href='https://github.com/dunbar12138/Audiovisual-Synthesis'> [GitHub]</a></span>
		  		  		</center>
		  		  	  </td>
						<td align=center width=150px>
						<center>
							<span style="font-size:24px"><a href='http://trinity.vision.cs.cmu.edu:12749/DB_GoogleDrive/ExemplarAutoencoder_ICLR2021.pdf'> [Paper]</a></span>
							</center>
						</td>

		  		  	 </tr>
	  			  <tr>
			  </table>

          </center>

  		  <br>


					We train <b>Exemplar Autoencoders</b> for infinitely many speakers using ~3 minutes of speech for an individual speaker without any additional information.
  					<center>
						<img src = "./images/exemplar_autoencoder_1.jpg" height="90px"></img></href><br>

					</center>
					<br>
					<span style="font-size:21px"><font color="darkred">Once trained, an <b>Exemplar Autoencoder</b> can be used for various applications such as:</font></span>

					<center>
						<img src = "./images/exemplar_autoencoder_2.jpg" height="190px"></img></href><br>
					</center>


  	              </td>

  		  </table>

      	  <br>
		  <hr>



  		  <table align=center width=850px>
	  		  <center><h1>Abstract</h1></center>
			</table>
			We present an unsupervised approach that converts the input speech of any individual into audiovisual streams of potentially-infinitely many output speakers. Our approach builds on simple autoencoders that project out-of-sample data onto the distribution of the training set. We use exemplar autoencoders to learn the voice, stylistic prosody, and visual appearance of a specific target exemplar speech. In contrast to existing methods, the proposed approach can be easily extended to an arbitrarily large number of speakers and styles using only 3 minutes of target audio-video data, without requiring  any training data for the input speaker.
		
			<br><br>
			<br>
			
			<table align=center width=600px>
				   <tr>
					 <td><a href="http://trinity.vision.cs.cmu.edu:12749/DB_GoogleDrive/ExemplarAutoencoder_ICLR2021.pdf"><img class="layered-paper-big" style="height:175px" src="./images/AudioRetargeting_firstpage.jpg"/></a></td>
					 <td><span style="font-size:14pt">K. Deng, A. Bansal, D. Ramanan<br>
					 Unsupervised Audiovisual Synthesis via Exemplar Autoencoders.<br>
					 In ICLR, 2021.</a>
					 </span>
					 </td>
					   </td>
				 </tr>
			   </table>
			 <br>

			 <table align=center width=600px>
				<tr>
					<td><span style="font-size:14pt"><center>
						<a href="./bib/audiovisual.txt">[Bibtex]</a>
					  </center></td>
				</tr>
			  </table>
			
		  <hr>

		  <center><h1>Summary Video</h1></center>

		  <br>
		  <center>
		  <p><iframe width="640" height="360" src="https://www.youtube.com/embed/O1_DHksQ9rY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p>
		  </center>
		  <br>
		  <hr>

		  <center><h1>Assitive Tool for Speech Impared</h1></center>
		  <center><h2>Towards Natural Voice for Speech Impaired</h2></center>
		  Here is a woman who lost her speaking voice due to throat cancer and now must rely on an electrolarynx to generate utterances. Our system provides them with a way to speak more naturally.
			
  
			<center><video width="640" height="360" controls>
			  <source src="videos/electrolarynx_example.mp4" type="video/mp4">
				  Your browser does not support the video element.
		  </video></center>



		  <center><h2>Stylize Text-To-Speech (TTS) Output</h2></center>
		  Our system can be used to stylize text-to-speech output without any transcribed speech data. 
		  <table align=center>
			<tbody>
				<tr>
					<th>Input Text</th>
					<th>TTS Output</th>
					<th>Our Stylized Output</th>
				</tr>
				<tr>
					<th>"This sentence is generated by a TTS system."</th>
					<th>
						<audio controls="">
							<source src="audios/TTS/TTS.wav" type="audio/wav">
							Your browser does not support the audio element.
						</audio>
					</th>
					<th>
						<audio controls="">
							<source src="audios/TTS/001_takeo.wav" type="audio/wav">
							Your browser does not support the audio element.
						</audio>
					</th>
				</tr>
			</tbody>
		</table>
		<br>


		<hr>

		<center><h1>Beyond Language Constraints</h1></center>
		We can even input voice in completely different language, e.g. Chinese and Hindi.
		<table align=center>
			<tbody>
				<tr>
					<th></th>
					<th>Input</th>
					<th>Output</th>
				</tr>
				<tr>
					<th>
						Chinese: 
					</th>
					<th>
						<audio controls="">
							<source src="audios/CrossLingual/input_chinese.wav" type="audio/wav">
							Your browser does not support the audio element.
						</audio>
					</th>
					<th>
						<audio controls="">
							<source src="audios/CrossLingual/oliver_output_chinese.wav" type="audio/wav">
							Your browser does not support the audio element.
						</audio>
					</th>
				</tr>
				<tr>
					<th>
						Hindi: 
					</th>
					<th>
						<audio controls="">
							<source src="audios/CrossLingual/input_hindi.m4a" type="audio/wav">
							Your browser does not support the audio element.
						</audio>
					</th>
					<th>
						<audio controls="">
							<source src="audios/CrossLingual/oliver_output_hindi.wav" type="audio/wav">
							Your browser does not support the audio element.
						</audio>
					</th>
				</tr>
			</tbody>
		</table>

		<hr>


		  <center><h1>Don't use your voice as a password!</h1></center>

		  <br>
		  <center>
		  <video width="640" height="380" controls>
			<source src="videos/demo/DemoVideo.mp4" type="video/mp4">
				Your browser does not support the video element.
		</video>
		  </center>
		  <br>
		  <hr>

		  <center><h1>Voice Conversion</h1></center> <br>
		  Our method can apply to in-the-wild audio, while embedding-based voice conversion methods (e.g. <a href="https://arxiv.org/abs/1905.05879">AutoVC</a>) struggle to capture the voice that differs from the training set. We contrast our method with the off-the-shelf model from <a href="https://arxiv.org/abs/1905.05879">AutoVC</a> by converting the input audio to John Oliver's voice.

		  <table align=center>
			<tbody>
			  <thead>
				  <th colspan="1"></th>

				  <th>Input-1</th>
				  <th>Input-2</th>
			  </thead>
			  <thead>
				<th colspan="1"> </th>

				<td>
					<audio controls="">
					<source src="./audios/1-input.m4a" type="audio/wav">
					Your browser does not support the audio element.
				</audio>
				</td>
				<td>
					<audio controls="">
					<source src="./audios/2-input.m4a" type="audio/wav">
					Your browser does not support the audio element.
				</audio>
				</td>
			  </thead>
			  <tr></tr><tr></tr><tr></tr><tr></tr>
			  <tr></tr><tr></tr><tr></tr><tr></tr>
			  <tr></tr><tr></tr><tr></tr><tr></tr>
			  <tr></tr><tr></tr><tr></tr><tr></tr>
			  <tr>
				<th>AutoVC: John Oliver <br>
				</th>	
				<td>
				<audio controls="">
					<source src="./audios/autovc/1-autovc.wav" type="audio/wav">
					Your browser does not support the audio element.
					</audio>
				</td>
				<td>
				<audio controls="">
					<source src="./audios/autovc/2-autovc.wav" type="audio/wav">
					Your browser does not support the audio element.
					</audio>
				</td>
				</tr> 
			  
			 
			  <tr>
				<th>Ours: John Oliver <br>
				</th>	
				<td>
				<audio controls="">
					<source src="./audios/our_results/1-johnoliver.wav" type="audio/wav">
					Your browser does not support the audio element.
					</audio>
				</td>
				<td>
				<audio controls="">
					<source src="./audios/our_results/2-johnoliver.wav" type="audio/wav">
					Your browser does not support the audio element.
					</audio>
				</td>
				</tr> 
			</tbody>
			</table>

			<br><br>
			Our exemplar autoencoders can be trained with only a modest amount of data, as little as a few minutes of speech. We show the results for a list of speakers from our CelebAudio dataset below (for research purpose only).

			<table align=center>
				<tbody>
					<tr>
						<th>
							<img class="rounded" src = "./images/celeb/takeo.png" height="80px"></img><br>
							Takeo Kanade <br>
							<audio controls="">
								<source src="./audios/our_results/1-takeokanade.wav" type="audio/wav">
								Your browser does not support the audio element.
								</audio>
								<br>
								<audio controls="">
									<source src="./audios/our_results/2-takeokanade.wav" type="audio/wav">
									Your browser does not support the audio element.
								</audio>
								<br>
						</th>
	
						<th>
							<img class="rounded" src = "./images/celeb/oprah.png" height="80px"></img><br>
							Oprah Winfrey <br>
							<audio controls="">
								<source src="./audios/our_results/1-oprahwinfrey.wav" type="audio/wav">
								Your browser does not support the audio element.
								</audio>
								<br>
								<audio controls="">
									<source src="./audios/our_results/2-oprah.wav" type="audio/wav">
									Your browser does not support the audio element.
								</audio>
								<br>
						</th>
						<th>
							<img class="rounded" src = "./images/celeb/carl.png" height="80px"></img><br>
							Carl Sagan <br>
							<audio controls="">
								<source src="./audios/our_results/1-carlsagan.wav" type="audio/wav">
								Your browser does not support the audio element.
								</audio>
								<br>
								<audio controls="">
									<source src="./audios/our_results/2-carlsagan.wav" type="audio/wav">
									Your browser does not support the audio element.
								</audio>
								<br>
						</th>
					</tr>
	
					<tr>
						<th>
							<br>
							<img class="rounded" src = "./images/celeb/alan.png" height="80px"></img><br>
							Alan Kay <br>
							<audio controls="">
								<source src="./audios/our_results/1-alankay.wav" type="audio/wav">
								Your browser does not support the audio element.
								</audio>
								<br>
								<audio controls="">
									<source src="./audios/our_results/2-alankay.wav" type="audio/wav">
									Your browser does not support the audio element.
								</audio>
								<br>
						</th>
	
						<th>
							<img class="rounded" src = "./images/celeb/claude.png" height="80px"></img><br>
							Claude Shannon <br>
							<audio controls="">
								<source src="./audios/our_results/1-claudeshannon.wav" type="audio/wav">
								Your browser does not support the audio element.
								</audio>
								<br>
								<audio controls="">
									<source src="./audios/our_results/2-claudeshannon.wav" type="audio/wav">
									Your browser does not support the audio element.
								</audio>
								<br>
						</th>

						<th>
							<img class="rounded" src = "./images/celeb/stephen.png" height="80px"></img><br>
							Stephen Hawking <br>
							<audio controls="">
								<source src="./audios/our_results/1-stephenhawking.wav" type="audio/wav">
								Your browser does not support the audio element.
								</audio>
								<br>
								<audio controls="">
									<source src="./audios/our_results/2-stephenhawking.wav" type="audio/wav">
									Your browser does not support the audio element.
								</audio>
								<br>
						</th>
					</tr>

				</tbody>
			</table>
				
			

		  <hr>


		<center><h1>Audiovisual Synthesis</h1></center>
		We can convert the input speech of any individual into an audiovisual stream of any learned speaker, e.g. John Oliver.

			

			<table align=center>
				<tbody>
					<tr>
						<th>Input</th>
						<th>Output</th>
					</tr>
					<tr>
						<th>
							<audio controls="">
								<source src="audios/3-input.m4a" type="audio/wav">
								Your browser does not support the audio element.
							</audio>
						</th>
						<th>
							<video width="240" height="240" controls>
								<source src="videos/3-output.mp4" type="video/mp4">
									Your browser does not support the video element.
							</video>
						</th>
					</tr>
				</tbody>
			</table>
			<br>



		  <hr>	

		  <center><h1>Audio-to-Video Synthesis</h1></center>

		  If we constrain the input within the training speaker even at inference time, the network then becomes capable of audio-to-video synthesis for a specific speaker. This application is useful for restoring the video records for some famous historical celebrities.
		  <br><br>
		  <center>
		  <p><iframe width="560" height="315" src="https://www.youtube.com/embed/cjXyJ3LW5Go" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p>
		  </center>

		  <center><br><span style="font-size:14px"><i>We take Winston Churchill's famous "end of beginning" speech as example. We only have the recordings of speech yet without video. However, with this technology, we can restore Churchill's talking head video based on the speech audio.</i><br><br><br>
		  </span></center>

		  <hr>	

		<center><h1>Broader Impact</h1></center>

        Our work falls in line with a body of work on content generation that retargets video content, often considered in the context of facial puppeteering. While there exist many applications in entertainment, there also exist many potentials for serious abuse. Our paper (Appendix A) includes a discussion on recommended policies for content generation, as well as a forensic study (Appendix B) that suggests that synthetic audio content can be identified as such with high accuracy.

		<br>

		<hr>
		  	
        <center><h1>Acknowledgements</h1></center>

        We thank Maneesh Agrawala and Fred Baik for the motivation to use samples of Electrolarynx for assistive applications. We thank Alan Black and David Forsyth for various discussion. We thank the authors of  <a href="https://github.com/auspicious3000/autovc">AutoVC</a> for their related work. We also thank members of Deva's Lab for helpful discussions. Finally, we thank the authors of <a href="http://richzhang.github.io/colorization/">Colorful Image Colorization</a> for this webpage design.


		<br><br>
        
		<script>
			var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
					document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
					</script><script src="./aayushb_wfiles/ga.js" type="text/javascript"></script> <script type="text/javascript">
			try {
					var pageTracker = _gat._getTracker("UA-39749944-1");
					pageTracker._trackPageview();
					} catch(err) {}
		</script>

</body>
</html>
 
